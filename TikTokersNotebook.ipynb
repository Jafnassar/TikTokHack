{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TikTok Hackathon: Data Cleaning & Qwen 3 8B Experimentation\n",
    "\n",
    "üèÜ **Advanced Review Classification with Qwen 3 8B LLM**\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Data Cleaning Pipeline** for restaurant review datasets\n",
    "2. **Exploratory Data Analysis** of review patterns and quality\n",
    "3. **Qwen 3 8B Model Experimentation** for review classification\n",
    "4. **Performance Benchmarking** across different categories\n",
    "5. **Advanced Advertisement Detection** development\n",
    "\n",
    "## üìä Dataset Overview\n",
    "\n",
    "We'll be working with multiple restaurant review datasets:\n",
    "- `data/Google Local Data/` - Google review datasets\n",
    "- `data/Google Map Reviews/reviews.csv` - Raw review data\n",
    "- `data/Google Map Reviews/reviews_cleaned.csv` - Pre-processed reviews\n",
    "- `data/Google Map Reviews/sepetcioglu_restaurant.csv` - Restaurant-specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Libraries imported successfully!\n",
      "üìÅ Current working directory: c:\\Users\\Administrator\\Documents\\Github Repos\\TikTokHack\n",
      "üéØ Ready for data cleaning and Qwen 3 8B experimentation!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(\"üìÅ Current working directory:\", os.getcwd())\n",
    "print(\"üéØ Ready for data cleaning and Qwen 3 8B experimentation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Data Loading & Initial Exploration\n",
    "\n",
    "Let's load all available datasets and explore their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded reviews_raw: 1100 rows, 6 columns\n",
      "   Columns: ['business_name', 'author_name', 'text', 'photo', 'rating']...\n",
      "‚úÖ Loaded reviews_cleaned: 1087 rows, 7 columns\n",
      "   Columns: ['business_name', 'author_name', 'text', 'photo', 'rating']...\n",
      "‚úÖ Loaded sepetcioglu: 29 rows, 3 columns\n",
      "   Columns: ['photo', 'rating', 'rating_category']\n",
      "\n",
      "üìä Total datasets loaded: 3\n"
     ]
    }
   ],
   "source": [
    "# Load all available datasets\n",
    "data_files = {\n",
    "    'reviews_raw': 'data/Google Map Reviews/reviews.csv',\n",
    "    'reviews_cleaned': 'data/Google Map Reviews/reviews_cleaned.csv',\n",
    "    'sepetcioglu': 'data/Google Map Reviews/sepetcioglu_restaurant.csv'\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for name, file_path in data_files.items():\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            datasets[name] = df\n",
    "            print(f\"‚úÖ Loaded {name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "            print(f\"   Columns: {list(df.columns)[:5]}{'...' if len(df.columns) > 5 else ''}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {name}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è File not found: {file_path}\")\n",
    "\n",
    "print(f\"\\nüìä Total datasets loaded: {len(datasets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Dataset: REVIEWS_RAW\n",
      "Shape: (1100, 6)\n",
      "Columns: ['business_name', 'author_name', 'text', 'photo', 'rating', 'rating_category']\n",
      "Sample data:\n",
      "                     business_name    author_name  \\\n",
      "0  Haci'nin Yeri - Yigit Lokantasi    Gulsum Akar   \n",
      "1  Haci'nin Yeri - Yigit Lokantasi  Oguzhan Cetin   \n",
      "\n",
      "                                                text  \\\n",
      "0  We went to Marmaris with my wife for a holiday...   \n",
      "1  During my holiday in Marmaris we ate here to f...   \n",
      "\n",
      "                                         photo  rating rating_category  \n",
      "0   dataset/taste/hacinin_yeri_gulsum_akar.png       5           taste  \n",
      "1  dataset/menu/hacinin_yeri_oguzhan_cetin.png       4            menu  \n",
      "--------------------------------------------------\n",
      "\n",
      "üîç Dataset: REVIEWS_CLEANED\n",
      "Shape: (1087, 7)\n",
      "Columns: ['business_name', 'author_name', 'text', 'photo', 'rating', 'rating_category', 'text_length']\n",
      "Sample data:\n",
      "                     business_name    author_name  \\\n",
      "0  Haci'nin Yeri - Yigit Lokantasi    Gulsum Akar   \n",
      "1  Haci'nin Yeri - Yigit Lokantasi  Oguzhan Cetin   \n",
      "\n",
      "                                                text  \\\n",
      "0  We went to Marmaris with my wife for a holiday...   \n",
      "1  During my holiday in Marmaris we ate here to f...   \n",
      "\n",
      "                                         photo  rating rating_category  \\\n",
      "0   dataset/taste/hacinin_yeri_gulsum_akar.png       5           taste   \n",
      "1  dataset/menu/hacinin_yeri_oguzhan_cetin.png       4            menu   \n",
      "\n",
      "   text_length  \n",
      "0          679  \n",
      "1          913  \n",
      "--------------------------------------------------\n",
      "\n",
      "üîç Dataset: SEPETCIOGLU\n",
      "Shape: (29, 3)\n",
      "Columns: ['photo', 'rating', 'rating_category']\n",
      "Sample data:\n",
      "                           photo  rating    rating_category\n",
      "0  sepetcioglu_restaurant/09.png       4              taste\n",
      "1  sepetcioglu_restaurant/01.png       5  indoor_atmosphere\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Quick dataset overview\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nüîç Dataset: {name.upper()}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Sample data:\")\n",
    "    print(df.head(2))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Data Cleaning Pipeline\n",
    "\n",
    "Now let's implement a comprehensive data cleaning pipeline for the review datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Data cleaning functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def clean_review_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess review text for better analysis\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove excessive punctuation\n",
    "    text = re.sub(r'[!]{2,}', '!', text)\n",
    "    text = re.sub(r'[?]{2,}', '?', text)\n",
    "    text = re.sub(r'[.]{3,}', '...', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def analyze_review_quality(text):\n",
    "    \"\"\"\n",
    "    Analyze review quality metrics\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return {\n",
    "            'length': 0,\n",
    "            'word_count': 0,\n",
    "            'quality_score': 0\n",
    "        }\n",
    "    \n",
    "    text = str(text)\n",
    "    words = text.split()\n",
    "    \n",
    "    return {\n",
    "        'length': len(text),\n",
    "        'word_count': len(words),\n",
    "        'quality_score': min(len(words) / 5, 10)  # Simple quality score\n",
    "    }\n",
    "\n",
    "print(\"üõ†Ô∏è Data cleaning functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Qwen 3 8B Model Experimentation\n",
    "\n",
    "Now let's experiment with the Qwen 3 8B model for review classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing Qwen 3 8B Review Classifier...\n",
      "ü§ñ Initializing Qwen Review Classifier\n",
      "üì± Device: cuda\n",
      "üéØ Categories: ['LEGITIMATE', 'SPAM', 'ADVERTISEMENTS', 'IRRELEVANT', 'FAKE_RANT', 'LOW_QUALITY']\n",
      "üîÑ Loading Qwen/Qwen3-8B model (optimized for RTX 4060)...\n",
      "üîÑ Loading Qwen/Qwen3-8B optimized for RTX 4060...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:18<00:00,  3.73s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Qwen 3 8B model loaded successfully on RTX 4060!\n",
      "‚úÖ Qwen 3 8B model loaded successfully!\n",
      "üì± Device: cuda\n",
      "üéØ Categories: ['LEGITIMATE', 'SPAM', 'ADVERTISEMENTS', 'IRRELEVANT', 'FAKE_RANT', 'LOW_QUALITY']\n"
     ]
    }
   ],
   "source": [
    "# Import and initialize Qwen 3 8B model\n",
    "import sys\n",
    "sys.path.append('.')  # Add current directory to path\n",
    "\n",
    "try:\n",
    "    from qwen_review_pipeline import QwenReviewClassifier\n",
    "    \n",
    "    print(\"ü§ñ Initializing Qwen 3 8B Review Classifier...\")\n",
    "    classifier = QwenReviewClassifier()\n",
    "    \n",
    "    print(\"üîÑ Loading Qwen/Qwen3-8B model (optimized for RTX 4060)...\")\n",
    "    classifier.load_model()\n",
    "    \n",
    "    print(\"‚úÖ Qwen 3 8B model loaded successfully!\")\n",
    "    print(f\"üì± Device: {classifier.device}\")\n",
    "    print(f\"üéØ Categories: {list(classifier.categories.keys())}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading Qwen model: {e}\")\n",
    "    print(\"‚ÑπÔ∏è Make sure qwen_review_pipeline.py is in the current directory\")\n",
    "    classifier = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Qwen 3 8B Classification\n",
      "========================================\n",
      "\n",
      "üìù Test 1: Great food and excellent service! Highly recommend this restaurant.\n",
      "ü§ñ Classification: LEGITIMATE (confidence: 0.71)\n",
      "\n",
      "üìù Test 2: AMAZING SALE! 50% OFF! Call 555-1234 NOW!\n",
      "ü§ñ Classification: LEGITIMATE (confidence: 0.71)\n",
      "\n",
      "üìù Test 2: AMAZING SALE! 50% OFF! Call 555-1234 NOW!\n",
      "ü§ñ Classification: SPAM (confidence: 0.60)\n",
      "\n",
      "üìù Test 3: The weather is nice today.\n",
      "ü§ñ Classification: SPAM (confidence: 0.60)\n",
      "\n",
      "üìù Test 3: The weather is nice today.\n",
      "ü§ñ Classification: IRRELEVANT (confidence: 0.72)\n",
      "\n",
      "üìù Test 4: Ok\n",
      "ü§ñ Classification: IRRELEVANT (confidence: 0.72)\n",
      "\n",
      "üìù Test 4: Ok\n",
      "ü§ñ Classification: LOW_QUALITY (confidence: 0.71)\n",
      "\n",
      "üìä Successfully tested 4 reviews!\n",
      "ü§ñ Classification: LOW_QUALITY (confidence: 0.71)\n",
      "\n",
      "üìä Successfully tested 4 reviews!\n"
     ]
    }
   ],
   "source": [
    "# Test sample review classification\n",
    "if classifier is not None:\n",
    "    print(\"üß™ Testing Qwen 3 8B Classification\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Sample test reviews\n",
    "    test_reviews = [\n",
    "        \"Great food and excellent service! Highly recommend this restaurant.\",\n",
    "        \"AMAZING SALE! 50% OFF! Call 555-1234 NOW!\",\n",
    "        \"The weather is nice today.\",\n",
    "        \"Ok\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for i, review in enumerate(test_reviews, 1):\n",
    "        print(f\"\\nüìù Test {i}: {review}\")\n",
    "        \n",
    "        try:\n",
    "            result = classifier.classify_review(review)\n",
    "            print(f\"ü§ñ Classification: {result['category']} (confidence: {result['confidence']:.2f})\")\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä Successfully tested {len(results)} reviews!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Qwen model not available for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¢ Advanced Advertisement Detection\n",
    "\n",
    "Test sophisticated advertisement detection capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Testing Advanced Advertisement Detection\n",
      "==================================================\n",
      "\n",
      "üìù Test 1: My yard was a disaster until I called GreenThumb Landscaping...\n",
      "Expected: ADVERTISEMENTS\n",
      "Predicted: ADVERTISEMENTS ‚úÖ\n",
      "\n",
      "üìù Test 2: Went to this restaurant last night. The food was decent but ...\n",
      "Expected: LEGITIMATE\n",
      "Predicted: ADVERTISEMENTS ‚úÖ\n",
      "\n",
      "üìù Test 2: Went to this restaurant last night. The food was decent but ...\n",
      "Expected: LEGITIMATE\n",
      "Predicted: LEGITIMATE ‚úÖ\n",
      "\n",
      "üìä Advertisement Detection Accuracy: 100.0%\n",
      "Predicted: LEGITIMATE ‚úÖ\n",
      "\n",
      "üìä Advertisement Detection Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Test advanced advertisement detection\n",
    "if classifier is not None:\n",
    "    print(\"üïµÔ∏è Testing Advanced Advertisement Detection\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    ad_tests = [\n",
    "        {\n",
    "            \"text\": \"My yard was a disaster until I called GreenThumb Landscaping. They offered me a free consultation and mentioned they only have a few spots left for their fall promotion. Call soon!\",\n",
    "            \"expected\": \"ADVERTISEMENTS\"\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"Went to this restaurant last night. The food was decent but nothing special. Service was friendly.\",\n",
    "            \"expected\": \"LEGITIMATE\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    correct = 0\n",
    "    for i, test in enumerate(ad_tests, 1):\n",
    "        print(f\"\\nüìù Test {i}: {test['text'][:60]}...\")\n",
    "        print(f\"Expected: {test['expected']}\")\n",
    "        \n",
    "        try:\n",
    "            result = classifier.classify_review(test['text'])\n",
    "            prediction = result['category']\n",
    "            status = \"‚úÖ\" if prediction == test['expected'] else \"‚ùå\"\n",
    "            print(f\"Predicted: {prediction} {status}\")\n",
    "            \n",
    "            if prediction == test['expected']:\n",
    "                correct += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    accuracy = correct / len(ad_tests) * 100\n",
    "    print(f\"\\nüìä Advertisement Detection Accuracy: {accuracy:.1f}%\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Qwen model not available for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "- ‚úÖ **Data Pipeline**: Successfully loaded and processed Google review datasets\n",
    "- ‚úÖ **Qwen 3 8B Integration**: Deployed state-of-the-art LLM for classification\n",
    "- ‚úÖ **6-Category Classification**: LEGITIMATE, SPAM, ADVERTISEMENTS, IRRELEVANT, FAKE_RANT, LOW_QUALITY\n",
    "- ‚úÖ **Advanced Detection**: Sophisticated advertisement detection capabilities\n",
    "- ‚úÖ **Hardware Optimization**: RTX 4060 optimized deployment\n",
    "\n",
    "This notebook demonstrates a complete workflow from data cleaning to advanced ML model deployment for the TikTok Hackathon challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
